Anthropic, Foundation models


Jump to Content

![Claude](https://files.readme.io/22c44d1-ant_logo_full.svg)

 __Guides __API Reference

* * *

Log In![Claude](https://files.readme.io/22c44d1-ant_logo_full.svg)

 __

Log In

Moon (Dark Mode)Sun (Light Mode)

 __Guides __API Reference

Search

## Introduction

  * Guide to Anthropic's prompt engineering resources
  * Getting access to Claude
  * Getting started with Claude
  * Your first chat with Claude
  * Configuring GPT prompts for Claude
  * Claude for Google Sheets
  * Glossary

## Prompt Design

  * Introduction to prompt design
  * Constructing a prompt
  * Optimizing your prompt

## Useful Hacks

  * Let Claude say "I don't know" to prevent hallucinations
  * Give Claude room to "think" before responding
  * Ask Claude to think step-by-step
  * Break complex tasks into subtasks
  * Prompt Chaining
  * Check Claude's comprehension
  * Ask Claude for rewrites

## Use Cases

  * Content Generation
  * Multiple Choice and Classification
  * Text Processing
  * Basic Text Analysis
  * Advanced Text Analysis
  * Roleplay Dialogue
  * Content Moderation

## Troubleshooting

  * Troubleshooting checklist
  * Human: and Assistant: formatting
  * Claude says it can't do something
  * Claude misses nuance
  * Claude responds in the wrong format
  * Claude is hallucinating

## Claude on Amazon Bedrock

  * Claude on Amazon Bedrock

# Claude says it can't do something

 __Suggest Edits

#

Give explanatory instructions

Explain the task you want Claude to complete to another person that doesn’t
have much context on what you’re trying to do. **Try giving _that very
explanation_ to Claude.** This can include giving it relevant background
context.

For example, if trying to get Claude to identify AI-generated text, one might
try:

Good Prompt

    
    
    Most text is currently produced by humans, but an increasing amount of text is produced by language models or AI assistants like yourself. I’m running an experiment to see if language models like yourself are able to distinguish between human-written text and text that is written by AI or language models, which could be text generated by yourself or by another language model. I’ll give you two examples of text labeled (A) and (B) and I want you to give some thoughts about which might be the model-generated text and which might be the human-generated text, and then to tell me which you think is most likely model-generated. Do you understand?
    

#

Have Claude repeat instructions back to you and say it understands them

You can give Claude some instructions, ask if it understands, and then have a
response that’s roughly _“Yes, I understand. You want me to {explanation of
instructions}. Is that right?”_ You can write this response on Claude's
behalf, or have the model generate it. For example:

Prompt to Get Claude to Explain the Instructions to the Human

    
    
    
    Human: I am going to give you a sentence from a legal contract and you need to edit it for me. The sentence will be a Definition of Permitted Recipients. You need to edit it so that consultants and advisors are included in the definition, but employees are not. You can reason through or explain anything you’d like before responding, but make sure at the very end, you end your answer with just the final answer in brackets. Do you understand the instructions?
    
    Assistant:
    

Output

    
    
    Yes, I understand the instructions. Here is the process I will follow:
    1) You will give me a sentence defining "Permitted Recipients" from a legal contract.
    2) I will edit the sentence to include consultants and advisors but exclude employees.
    3) I will provide the final edited sentence enclosed in brackets at the end of my response.
    Is that correct?
    

If Claude's explanation is correct, you can combine it with the original
prompt. (If it is not correct, you should revise it first then combine it with
the original prompt.)

Combined Prompt

    
    
    
    Human: I am going to give you a sentence from a legal contract and you need to edit it for me. The sentence will be a Definition of Permitted Recipients. You need to edit it so that consultants and advisors are included in the definition, but employees are not. You can reason through or explain anything you’d like before responding, but make sure at the very end, you end your answer with just the final answer in brackets. Do you understand the instructions?
    
    Assistant: Yes, I understand the instructions. Here is the process I will follow:
    1) You will give me a sentence defining "Permitted Recipients" from a legal contract.
    2) I will edit the sentence to include consultants and advisors but exclude employees.
    3) I will provide the final edited sentence enclosed in brackets at the end of my response.
    Is that correct?
    
    Human: Yes. Here is the sentence: "Your Representatives shall include your advisors, directors, employees and accountants."
    
    Assistant:
    

This can be a way of getting Claude to comply with tasks it otherwise won’t
complete, e.g. if the model will by default say “I don’t know how to do that”
then a mini dialogue at the beginning where the model **agrees to do the
thing** can help get around this.

 __Updated 6 months ago

* * *

  * __Table of Contents
  *     * Give explanatory instructions
    * Have Claude repeat instructions back to you and say it understands them

