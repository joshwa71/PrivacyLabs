Anthropic, Foundation models


Jump to Content

![Claude](https://files.readme.io/22c44d1-ant_logo_full.svg)

 __Guides __API Reference

* * *

Log In![Claude](https://files.readme.io/22c44d1-ant_logo_full.svg)

 __

Log In

Moon (Dark Mode)Sun (Light Mode)

 __Guides __API Reference

Search

## Introduction

  * Guide to Anthropic's prompt engineering resources
  * Getting access to Claude
  * Getting started with Claude
  * Your first chat with Claude
  * Configuring GPT prompts for Claude
  * Claude for Google Sheets
  * Glossary

## Prompt Design

  * Introduction to prompt design
  * Constructing a prompt
  * Optimizing your prompt

## Useful Hacks

  * Let Claude say "I don't know" to prevent hallucinations
  * Give Claude room to "think" before responding
  * Ask Claude to think step-by-step
  * Break complex tasks into subtasks
  * Prompt Chaining
  * Check Claude's comprehension
  * Ask Claude for rewrites

## Use Cases

  * Content Generation
  * Multiple Choice and Classification
  * Text Processing
  * Basic Text Analysis
  * Advanced Text Analysis
  * Roleplay Dialogue
  * Content Moderation

## Troubleshooting

  * Troubleshooting checklist
  * Human: and Assistant: formatting
  * Claude says it can't do something
  * Claude misses nuance
  * Claude responds in the wrong format
  * Claude is hallucinating

## Claude on Amazon Bedrock

  * Claude on Amazon Bedrock

# Basic Text Analysis

 __Suggest Edits

You can give Claude many types of textâ€”articles, emails, meeting transcripts,
database recordsâ€”and it can help you digest, explain, and answer questions
about them. With its 100k token context window, Claude can analyze tens of
thousands of words.

Here are a few basic applications of this capability.

* * *

##

Evaluating text similarity

We can ask Claude if two pieces of text are roughly the same in meaning.

Prompt for Checking Text Similarity

    
    
    
    Human: You are going to be checking whether two sentences are roughly saying the same thing.
    
    Here's the first sentence: "{{SENTENCE1}}"
    
    Here's the second sentence: "{{SENTENCE2}}"
    
    Please begin your answer with "[YES]" if they're roughly saying the same thing or "[NO]" if they're not.
    
    Assistant: [
    

By starting Claude's response ourselves with `[`, we help "reinforce" the
prompt instruction to use that format and to start its response with yes or
no.

* * *

##

Answering questions about a text

Here, we give Claude a meeting transcript and a question for it to answer
using the transcript.

Prompt for Text Q&A

    
    
    
    Human: I'm going to give you an example transcript from a meeting and then I'm going to ask you some questions about the transcript.
    
    <transcript>
    {{TEXT}}
    </transcript>
    
    Here is the first question:  {{QUESTION}}
    
    Assistant:
    

> ðŸ’¡
>
> Citing sources
>
> For an example prompt where we ask Claude to answer a question based on a
> document _and_ cite sources for its answer, see Advanced Text Analysis.

 __Updated 6 months ago

* * *

  * __Table of Contents
  *     * Evaluating text similarity
    * Answering questions about a text

